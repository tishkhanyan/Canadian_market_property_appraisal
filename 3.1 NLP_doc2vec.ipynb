{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property appraisal ML project.\n",
    "## Phase 2: NLP processing the 'Public Remarks' Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading one file\n",
    "df = pd.read_csv('F20 P1.csv', index_col=None, header=0)\n",
    "\n",
    "# reading part of the files from Detached June 2020-2021 folder\n",
    "\n",
    "# data_files = ['F20 P1.csv', 'F20 P2.csv', 'F30 P1.csv', 'F30 P2.csv', 'F50 P1.csv', 'F50 P2.csv']\n",
    "# data_list = []\n",
    "\n",
    "# for filename in data_files:\n",
    "#     df_current = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     data_list.append(df_current)\n",
    "\n",
    "# df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "\n",
    "# deleting yellow columns\n",
    "df.drop(['Status', 'For Tax Year', 'Gross Taxes', 'Original Price', 'List Price', 'GST Incl'], axis = 1, inplace = True)\n",
    "\n",
    "# # size of our dataset\n",
    "# print('Our dataset has', len(df), 'data lines and', len(df.columns.tolist()), 'features:')\n",
    "# print('\\n')\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features dropped.\n",
      "\n",
      "\n",
      "Features left:\n",
      "['Address', 'S/A', 'Price', 'Sold Date', 'Days On Market', 'Age', 'Area', 'Total Bedrooms', 'Total Baths', 'Lot Sz (Sq.Ft.)', 'Floor Area -Grand Total', 'Driveway Finish', 'Floor Area - Unfinished', 'Foundation', 'Floor Area Fin - Basement', 'Zoning', 'Parking Places - Covered', '# Rms', 'No. Floor Levels', 'Frontage - Feet', 'Depth', 'Type', 'Public Remarks']\n",
      "\n",
      "\n",
      "Now we have 23 features and their types:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataTypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Address</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S/A</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold Date</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days On Market</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bedrooms</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Baths</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Sz (Sq.Ft.)</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area -Grand Total</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driveway Finish</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area - Unfinished</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area Fin - Basement</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoning</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parking Places - Covered</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Rms</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. Floor Levels</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frontage - Feet</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Remarks</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          DataTypes\n",
       "Address                      object\n",
       "S/A                          object\n",
       "Price                        object\n",
       "Sold Date                    object\n",
       "Days On Market                int64\n",
       "Age                           int64\n",
       "Area                         object\n",
       "Total Bedrooms                int64\n",
       "Total Baths                   int64\n",
       "Lot Sz (Sq.Ft.)              object\n",
       "Floor Area -Grand Total      object\n",
       "Driveway Finish              object\n",
       "Floor Area - Unfinished      object\n",
       "Foundation                   object\n",
       "Floor Area Fin - Basement    object\n",
       "Zoning                       object\n",
       "Parking Places - Covered    float64\n",
       "# Rms                         int64\n",
       "No. Floor Levels              int64\n",
       "Frontage - Feet              object\n",
       "Depth                        object\n",
       "Type                         object\n",
       "Public Remarks               object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the columns with more than 90% NAs\n",
    "moreThan = []\n",
    "\n",
    "for feature in df:\n",
    "    if df[feature].isna().sum() / df.shape[0] > 0.9:\n",
    "        moreThan.append(feature)\n",
    "        print(\"Dropping the feature:\", feature)\n",
    "df.drop(moreThan, axis = 1, inplace = True)\n",
    "\n",
    "if moreThan == []:\n",
    "    print('No features dropped.')\n",
    "print('\\n')\n",
    "\n",
    "# dropping the columns that are not insightful: Days On Market, Public Remarks\n",
    "# df1.drop(['Sold Date', 'Public Remarks'], axis=1, inplace = True)\n",
    "# df.drop(['Public Remarks'], axis=1, inplace = True)\n",
    "\n",
    "columns_names = df.columns.tolist()\n",
    "\n",
    "print(\"Features left:\")\n",
    "print(columns_names)\n",
    "print('\\n')\n",
    "print(\"Now we have\", len(columns_names), \"features and their types:\")\n",
    "\n",
    "# types of our columns\n",
    "pd.DataFrame(df.dtypes, columns=['DataTypes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hereafter we're working only with the \"Public Remarks\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Investor's alert. 3 bedroom tenanted home with...\n",
       "1      WHY RENT? Apartment size, 1 bedroom, modern, e...\n",
       "2      INVESTORS and FIRST TIME HOME BUYERS ALERT! 2 ...\n",
       "3      **LARGE 8255 sqft LOT****PERFECT FOR INVESTORS...\n",
       "4      Tastefully renovated 2 bed 1bath house with de...\n",
       "                             ...                        \n",
       "553    6,500 SF of executive living. Exquisitely buil...\n",
       "554    2.07 Acre Site Great Development Potential Lan...\n",
       "555    Magnificently New Luxury home by SOOD DEVELOPM...\n",
       "556    LOCATION, LOCATION!! Hobby Farm in South Pt. K...\n",
       "557    Location! Location! Location! Port Kells futur...\n",
       "Name: Public Remarks, Length: 558, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_column = df['Public Remarks'].copy()\n",
    "\n",
    "nlp_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mountain / river views and a beautiful sized south facing seven , zero sqft private backyard make this a home you will not want to miss . this well cared for fourbd twobath home is headache - free with a new roof , new h / w tank , and new furnace . the main living area boasts a one hundred and eighty - nine sqft wrap - around balcony that is perfect for enjoying those sunny days and the basement boasts a walkout onebd suite with shared laundry . located in one of the nicest neighborhoods of bolivar heights and is the perfect building lot in the future . single garage , school nearby , quick access to patullo bridge . near surrey central mall . the best - priced starter home on the market and a solid investment for a future custom home !'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_column = df['Public Remarks'].copy()\n",
    "\n",
    "# a bit of cleaning: filling with NaN's where not available, changing some words\n",
    "\n",
    "nlp_column = nlp_column.fillna('0')\n",
    "nlp_column_prep_1 = nlp_column.str.replace('&',' and ')\n",
    "nlp_column_prep_1 = nlp_column_prep_1.str.replace('%',' percent')\n",
    "nlp_column_prep_1 = nlp_column_prep_1.str.replace('*','')\n",
    "\n",
    "\n",
    "# replace all the digits with corresponding words: 5 -> five\n",
    "import re\n",
    "import num2words\n",
    "\n",
    "# this removes thousands delimiter. so 6,550 will be 6500\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+),(\\d+)', r'\\1\\2', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# # # these two lines change 4'' or 4 '' to 4 inch\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+) \\'\\'', r' \\1 inch ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+)\\'\\'', r' \\1 inch ', paragraph) for paragraph in nlp_column_prep_1]                           \n",
    "                       \n",
    "# these two lines change 3' or 3 ' to 3 feet\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+)\\'', r' \\1 foot', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+) \\'', r' \\1 foot', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# this line changes feetx/feet x to feet by; inchx/inch x to inch by; ft. x to foor by\n",
    "nlp_column_prep_1 = [paragraph.replace('footx', 'feet by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('foot x', 'foot by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('inchx', 'inch by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('inch x', 'inch by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('ft. x', 'foot by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('ft.', 'foot') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# change $number.00 to number dollars\n",
    "nlp_column_prep_1 = [re.sub(r'\\$(\\d+)\\.(\\d+)', r'\\1 dollars ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'\\$(\\d+)', r'\\1 dollars ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# here I MANUALLY change some of the non correct abbreviation for sqft and hwy\n",
    "nlp_column_prep_1 = [paragraph.replace('sg ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('s.f.', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('square-foot', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('sq ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('sq.ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "nlp_column_prep_1 = [paragraph.replace('hwy', 'highway') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# this line changes all the numbers to their words\n",
    "nlp_column_prep_1 = [re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), paragraph) for paragraph in nlp_column]\n",
    "\n",
    "# tokenize these comments\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "nlp_column_prep_2 = [preprocess(paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "nlp_column_prep_2[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a function to get the say 3 most similar paragraphs to the given one\n",
    "\n",
    "def most_similar(doc_id, similarity_matrix, matrix):\n",
    "    print (f'Similar Documents using {matrix}:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1][:4]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[:4]\n",
    "    for ix in similar_ix:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        print('\\n')\n",
    "        print ({nlp_column[ix]})\n",
    "        print (f'{matrix} Score : {similarity_matrix[doc_id][ix]}')\n",
    "    print('\\n')\n",
    "    print('Similar paragraph indexes:', similar_ix[1:])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Doc2Vec model\n",
    "\n",
    "Now we build a Doc2Vec model which is one of the best NLP tools that gives opportunity to get the similarities between texts (exactly between paragraphs!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(paragraph), tags=[i]) for i, paragraph in enumerate(nlp_column_prep_2)]\n",
    "\n",
    "vect_len = 50\n",
    "\n",
    "model_d2v = Doc2Vec(vector_size=vect_len,alpha=0.025, min_count=1)\n",
    "  \n",
    "model_d2v.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(vect_len):\n",
    "    model_d2v.train(tagged_data,\n",
    "                total_examples=model_d2v.corpus_count,\n",
    "                epochs=model_d2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_embeddings=np.zeros((np.shape(nlp_column_prep_2)[0],vect_len))\n",
    "\n",
    "for i in range(len(paragraph_embeddings)):\n",
    "    paragraph_embeddings[i]=model_d2v.dv[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities = cosine_similarity(paragraph_embeddings)\n",
    "pairwise_differences = euclidean_distances(paragraph_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are interested in this paragraph with index: 143\n",
      "Welcome to this gorgeous 4 Bedroom, 2 Washroom Renovated Rancher with back lane access sitting on a big 7380 sqft lot. Detached garage at rear along with a separate oversized shed for extra storage. Central and convenient location, close to both levels of school and Guildford mall, very quiet street. Private fenced yard for kids to play or summer fun. Easy access to Vancouver and Highway #1. First Showing Saturday 2-4pm open house.\n",
      "\n",
      "\n",
      "Similar Documents using Cosine Similarity:\n",
      "\n",
      "\n",
      "{\"Great Potential: The big lot (9660 sqft) is eligible to be subdivided into two lots, buyer's agent to verify with the city hall. Most trees beside house are approved to cut down. The property is located in a quiet and convenient neighborhood. Complete renovation and upgraded appliances have been done in 2017, with 3 bedrooms and 2 full baths up and 3 bedrooms and 2 full baths down. potential 2 Basement suites are great mortgage helper. Call/text for the showing. Open House: Aug 01, Saturday  2:30 - 4:30pm\"}\n",
      "Cosine Similarity Score : 0.590357739065926\n",
      "\n",
      "\n",
      "{\"Invest or build!! Great central location close to parks, transit and the rapid growing downtown city core. Build your dream home here on the large, level, 66' x 134' (8800 sqft) lot with lane access. Lots of new builds close by with new storm drain installed in 2014 at a lower depth. This large 2200 sqft 3 bed 1 bath multi level home shows very well and is a great investment with tons of future potential. Open house Saturday July 25, 2020 1-5. Gloves and masks Mandatory. Walk ins welcomed but first priority to appts. One group at a time Covid protocols in place\"}\n",
      "Cosine Similarity Score : 0.588026493790708\n",
      "\n",
      "\n",
      "{'Well maintained CASH COW or live with reduced mortgage payment stress! This property is rented to great tenants top (main house) and bottom (2 suites). Well kept, spacious 2850 SF basement entry home in Birdland, Bolivar Heights. 7200 sf flat rectangular lot with total 6 bedrooms, 4 baths with open floor plan. Two suites below both 1 bedrooms well maintained (1+1). Double glazed windows. Real Hardwood floors & storage shed and lots of parking in open driveway for 6 vehicles. Steps to Robin Park, close to schools, Hwy #1, Guildford Mall and transit'}\n",
      "Cosine Similarity Score : 0.5876963542109306\n",
      "\n",
      "\n",
      "Similar paragraph indexes: [280 111 123]\n",
      "\n",
      "\n",
      "Similar Documents using Euclidean Distance:\n",
      "\n",
      "\n",
      "{'Great opportunity to own this detached home.'}\n",
      "Euclidean Distance Score : 15.340447884233441\n",
      "\n",
      "\n",
      "{'7,500 sqft corner lot along 108th Avenue. Call for more info.'}\n",
      "Euclidean Distance Score : 15.608631276394863\n",
      "\n",
      "\n",
      "{'BUILDERs AND INVESTORS This Cozy rancher sitting on a flat ,Clear ,Rectangular lot. House have three good size bedrooms and 2 full washroom . With very open plan no shortage of light inside. 10 Minutes waking distance to Gateway skytrain station .Close to Both levels of school. SFU,SURREY CENTRAL,NEW LIBRARY. Most Developing area in surrey. Enclosed covered sundeck to enjoy even in rain.Have separate garage with workshop to do your weekend project. New Furnace .Hurry before its gone !'}\n",
      "Euclidean Distance Score : 16.307406344964505\n",
      "\n",
      "\n",
      "Similar paragraph indexes: [ 13   7 169]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# idx = np.random.randint(len(nlp_column))\n",
    "idx = 143\n",
    "print(\"We are interested in this paragraph with index:\", idx)\n",
    "print(nlp_column[idx])\n",
    "print('\\n')\n",
    "\n",
    "most_similar(idx, pairwise_similarities, 'Cosine Similarity')\n",
    "most_similar(idx, pairwise_differences, 'Euclidean Distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace snetence embedding generator model\n",
    "\n",
    "Now we build paragraph embeddings using one of the HuggingFace transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v1')\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_embeddings_HF = model.encode(nlp_column_prep_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have  558 public remarks\n",
      "Each of them is transformed to 384 shape numeric vector.\n",
      "An important and very useful feauter is that these embedding vectors are normed:\n",
      "Min value of one of them: -0.17637709\n",
      "Max value of the above vector: 0.15290494\n",
      "Dot product, i.e. the length of it: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"We have \", paragraph_embeddings_HF.shape[0], \"public remarks\")\n",
    "print(\"Each of them is transformed to\", paragraph_embeddings_HF.shape[1],\"shape numeric vector.\")\n",
    "\n",
    "print(\"An important and very useful feauter is that these embedding vectors are normed:\")\n",
    "print(\"Min value of one of them:\",paragraph_embeddings_HF[3].min())\n",
    "print(\"Max value of the above vector:\",paragraph_embeddings_HF[3].max())\n",
    "print(\"Dot product, i.e. the length of it:\", np.dot(paragraph_embeddings_HF[3],paragraph_embeddings_HF[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are interested in this paragraph with index: 12\n",
      "Mountain/River views and a beautiful sized SOUTH FACING 7,000 sqft private backyard make this a home you will not want to miss. This well cared for 4bd 2bath home is headache-free with a NEW roof, NEW H/W tank, and NEW furnace. The main living area boasts a 189 sqft wrap-around balcony that is perfect for enjoying those sunny days and the basement boasts a WALKOUT 1bd suite with shared laundry. Located in one of the nicest neighborhoods of Bolivar Heights and is the perfect building lot in the future. Single garage, school nearby, quick access to Patullo Bridge. Near Surrey Central Mall. The best-priced starter home on the market and a solid investment for a future custom home!\n",
      "\n",
      "\n",
      "Similar Documents using Cosine Similarity:\n",
      "\n",
      "\n",
      "{'Amazing views! Enjoy mountain & river view from this area. lovely 3 bedroom & 1 bath upstairs, living, dining room & kitchen. Downstairs has unauthorized bright 2 br rental suite with separate entrance. Basement has own laundry. Lots of renovations make this home sparkle!.. Close to schools, parks, shops & great commuter access 2 blocks from North Delta! Open House Sun Aug 2nd 2-4 PM'}\n",
      "Cosine Similarity Score : 0.6580483317375183\n",
      "\n",
      "\n",
      "{\"Wow. Rarely available. AMAZING CITY and MOUNTAIN VIEWS from this bright four bedroom home. You'll love this very large square 9,250 square foot lot on the quiet 135A Street in sough-tafter BOLIVAR HEIGHTS neighbourhood.   On the best side of 135A street, look over all your neighbours below to enjoy unobstructed views from BOTH the main floor AND from the basement floor.  This home has gorgeous original hardwood floors, 2 fireplaces, huge fenced backyard, and combined parking for 4 in the garage and driveway, plus LOTS of street parking.  Room for a rentable income helper. Live in this home, rent it, OR build your luxury dream home. Pro tip...Put a hot tub on the roof of your new home.  Ask for link to our aerial video. Call before it's gone.\"}\n",
      "Cosine Similarity Score : 0.6314297914505005\n",
      "\n",
      "\n",
      "{'Amazing views! Enjoy mountain & river view from this area. lovely 3 bedroom & 1 bath upstairs, living, dining room & kitchen. Downstairs has unauthorized bright Bachelor  rental suite with separate entrance. Basement has  laundry and possibility to have 1+1 rental suites Lots of renovations make this home sparkle, which includes new kitchen 2 updated electrical panels new windows and much more Close to schools, parks, shops & great commuter access 2 blocks from North Delta. Open House Sat Sep 19th 2-4 PM'}\n",
      "Cosine Similarity Score : 0.6197361946105957\n",
      "\n",
      "\n",
      "Similar paragraph indexes: [212 187 149]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairwise_similarities = cosine_similarity(paragraph_embeddings_HF)\n",
    "\n",
    "# idx = 461\n",
    "idx = 12\n",
    "print(\"We are interested in this paragraph with index:\", idx)\n",
    "print(nlp_column[idx])\n",
    "print('\\n')\n",
    "\n",
    "most_similar(idx, pairwise_similarities, 'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are interested in this paragraph with index: 221\n",
      "Long Water Frontage,  potential revenue from water front location and fully usable land. On this peaceful island, safer for growing ideally precious plants! Very flat and   Nice setting with gorgeous view of mountain, just short walk to the free ferry crossing even when you are the only passenger (please check ferry schedule for details). Easy access to TransCanada highway one, Highway 15 and Highway 17, just minutes away from Guildford Town Center and Surrey City Center, Pacific Academy, Fraser Heights Secondary, and many more. Extremely low property tax and easy maintenance for this valued land near Vancouver, a dream place for weekend, investment, self sufficient life style by growing your own vegetable, livestocks,  etc....however, easy access to urban amenities  if needed.\n",
      "\n",
      "\n",
      "Similar Documents using Cosine Similarity:\n",
      "\n",
      "\n",
      "{'Oh my views!! Fraser River, Pattullo Bridge, New Westminster, and the mountains. Private corner lot with 60x131ft of frontage and a huge 4 bedroom suite great for that mortgage helper!! Many new updates include; newer floors(laminate/tile), newer deck, newer windows, doors, cabinets, mouldings, large shed, plumbing and light fixtures, 2 sets of washer/dryer, two full baths up, a great holding property or starter home now to build on later. Easy access to main highways, bridges & Skytrain. Catchment schools; Prince Charles Elementary, L.A. Matheson Secondary. Walking distance to Saint Mary Coptic Orthodox Church and Khalsa School.'}\n",
      "Cosine Similarity Score : 0.5969347953796387\n",
      "\n",
      "\n",
      "{\"Beautiful location. Park on 2 sides with waterpark, 35 minutes to Downtown Vancouver, near both levels of school. This is a custom designed luxury home with all amenities close by on over 9500 sq. ft. lot. Large master bedroom has an 8x8 sitting area, gas fireplace, huge closet and balcony facing the park. Sunken living room, office, wok kitchen, maple cabinets, huge sundeck, 9' ceilings, radiant heat, almost 5400 sq. ft. with garage, 3 bedroom basement suite with separate entry and a lot more! Seller is willing to trade for a house priced under $1 million.\"}\n",
      "Cosine Similarity Score : 0.5794631838798523\n",
      "\n",
      "\n",
      "{'Affordable living in Surrey Central with excellent access to Pattullo Bridge, Skytrain, SFPR and the new North Surrey Sport & Ice Complex.  Quiet neighbourhood with traffic calming features, this corner-lot home is across the street from Poplar Park with a three- season mountain view overlooking the Fraser River, Coquitlam and North Shore mountains.  South-facing, low-maintenance back yard with rear lane access and large sunroom with screened windows.  Attached workshop / storage plus open lean-to.  Great open floor plan.  Master bedroom on main with large closet and bonus storage above.  Security system; new roof 2017; new hot water tank 2015.'}\n",
      "Cosine Similarity Score : 0.5788891315460205\n",
      "\n",
      "\n",
      "Similar paragraph indexes: [186 482   5]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's take another random passage\n",
    "\n",
    "pairwise_similarities = cosine_similarity(paragraph_embeddings_HF)\n",
    "\n",
    "idx = np.random.randint(len(nlp_column))\n",
    "print(\"We are interested in this paragraph with index:\", idx)\n",
    "print(nlp_column[idx])\n",
    "print('\\n')\n",
    "\n",
    "most_similar(idx, pairwise_similarities, 'Cosine Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it is obvious that this processing of public remarks is better than the others developed before. So, we'll work with this in the next steps of project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make predictions of the prices of properties just using their Public Remarks (this is possible!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm just using the same ML model developed in 1. baseline sulution file\n",
    "\n",
    "y = df['Price'].str.replace('$','').str.replace(',','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions take as inputs the real and predicted values \n",
    "\n",
    "# 1. % of values are predicted for <= 2, 3, 5, 10, 20 % of accuracy\n",
    "def results_score(real_values, predictions):\n",
    "    percentage_list = [2, 3, 5, 10, 20]\n",
    "    \n",
    "    for percentage in percentage_list:\n",
    "        diff_list = []\n",
    "        diff_list = np.abs((np.array(real_values) - np.round(predictions,1)))/np.array(real_values) * 100\n",
    "        print(np.round(np.shape(np.where(np.round(diff_list,2) <= percentage))[1] / np.shape(real_values)[0] * 100, 1), '% of predited values has <=', percentage, '% accuracy.')\n",
    "        \n",
    "# 2. Mean absolute percentage error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# 3. Median absolute percentage error\n",
    "def median_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.median(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitted\n"
     ]
    }
   ],
   "source": [
    "# now we make an ensemble learning using RandomForest, DecisionTree and XBG regressors and Ridge regression below that\n",
    "# one might use more regressors but this will not significantly improve the results. even it might generate worst results\n",
    "\n",
    "from sklearn.linear_model import Ridge, LassoCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(paragraph_embeddings_HF, y, test_size=0.2, random_state=42)\n",
    "regr = 0\n",
    "\n",
    "### Model\n",
    "estimators = [\n",
    "#     ('lr1', LassoCV()),\n",
    "    ('lr2', RandomForestRegressor(n_estimators=7, random_state = 42, n_jobs=-1)),\n",
    "    ('lr3', xgb.XGBRegressor(n_estimators=70, learning_rate=0.1, gamma=0, subsample=0.75, colsample_bytree=1)),\n",
    "    ('lr4', DecisionTreeRegressor(random_state=0))\n",
    "    ]\n",
    "regr = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print('model fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for test dataset:\n",
      "9.8 % of predited values has <= 2 % accuracy.\n",
      "12.5 % of predited values has <= 3 % accuracy.\n",
      "19.6 % of predited values has <= 5 % accuracy.\n",
      "33.9 % of predited values has <= 10 % accuracy.\n",
      "54.5 % of predited values has <= 20 % accuracy.\n",
      "\n",
      "\n",
      "Results for train dataset (to check if we have overfitting or the results are comparable with those on test dataset):\n",
      "40.4 % of predited values has <= 2 % accuracy.\n",
      "56.3 % of predited values has <= 3 % accuracy.\n",
      "78.5 % of predited values has <= 5 % accuracy.\n",
      "97.8 % of predited values has <= 10 % accuracy.\n",
      "99.6 % of predited values has <= 20 % accuracy.\n"
     ]
    }
   ],
   "source": [
    "# now we show the results:\n",
    "print('Results for test dataset:')\n",
    "results_score(y_test, np.round(regr.predict(X_test),1))\n",
    "\n",
    "print('\\n')\n",
    "print('Results for train dataset (to check if we have overfitting or the results are comparable with those on test dataset):')\n",
    "results_score(y_train, np.round(regr.predict(X_train),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving moreless the same results as the doc2vec embeddings, but the HFones are normed and this will be very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take baseline solution, add these embeddings and train a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "# df1.drop(['Public Remarks'], axis=1, inplace = True)\n",
    "df1.drop(['Address'], axis=1, inplace = True)\n",
    "\n",
    "df1['Price'] = df1['Price'].str.replace('$','').str.replace(',','').astype(int)\n",
    "\n",
    "df1['Sold Date'] = df1['Sold Date'].str.split(\"/\")\n",
    "df1['Sold Year'] = df1['Sold Date'].str[2]\n",
    "df1['Sold Month'] = df1['Sold Date'].str[0]\n",
    "df1.drop(['Sold Date'], axis=1, inplace = True)\n",
    "\n",
    "df1['Age'] = df1['Age'].fillna(-1).astype(int)\n",
    "df1.loc[df1['Age'] > 150, 'Age'] = 150\n",
    "\n",
    "df1['Lot Sz (Sq.Ft.)'] = df1['Lot Sz (Sq.Ft.)'].str.replace(',', '').astype(float)\n",
    "# df1.drop(df1[df1['Lot Sz (Sq.Ft.)'] > 50000].index, inplace = True)\n",
    "# df1.drop(df1[df1['Lot Sz (Sq.Ft.)'] < 100].index, inplace = True)\n",
    "\n",
    "df1['Floor Area -Grand Total'] = df1['Floor Area -Grand Total'].str.replace(',', '').astype(int)\n",
    "\n",
    "# df1['Driveway Finish'] = df1['Driveway Finish'].astype(str)\n",
    "\n",
    "df1['Floor Area - Unfinished'] = df1['Floor Area - Unfinished'].str.replace(',', '').astype(int)\n",
    "\n",
    "df1['Foundation'] = df1['Foundation'].astype(str)\n",
    "\n",
    "df1['Floor Area Fin - Basement'] = df1['Floor Area Fin - Basement'].str.replace(',', '').astype(float)\n",
    "\n",
    "df1['Zoning'] = df1['Zoning'].astype(str)\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('A1', 'A-1')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('A2', 'A-2')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('1ACRER', 'RA')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('1 AR', 'RA')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RF13', 'RF-13')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RHG', 'RH-G')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RS-1', 'RS1')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('SING/F', 'SING')\n",
    "\n",
    "df1['Parking Places - Covered'] = df1['Parking Places - Covered'].fillna(-1) ### or -1\n",
    "\n",
    "df1.loc[df1['No. Floor Levels'] > 10, 'No. Floor Levels'] = -1\n",
    "\n",
    "df1['Frontage - Feet'] = df1['Frontage - Feet'].str.replace(',', '').astype(float)\n",
    "df1['Frontage - Feet'] = df1['Frontage - Feet'].fillna(-1) ### or -1\n",
    "\n",
    "df1 = df1.drop(['Depth'], axis=1)\n",
    "\n",
    "df1['new feature 1'] = (df1['Total Bedrooms'] + df1['# Rms'])\n",
    "\n",
    "df1['Total Baths'] = df1['Total Baths'].astype(str)\n",
    "df1['# Rms'] = df1['# Rms'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete outliers\n",
    "\n",
    "first_quartile = df1.quantile(q=0.25)\n",
    "third_quartile = df1.quantile(q=0.75)\n",
    "IQR = third_quartile - first_quartile\n",
    "\n",
    "outliers = df1[(df1 > (third_quartile + 1.5 * IQR)) | (df1 < (first_quartile - 1.5 * IQR))].count(axis=1)\n",
    "outliers.sort_values(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "outliers = outliers.head(np.int(np.ceil(df.shape[0]/20)))\n",
    "df1.drop(outliers.index, inplace=True)\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_column = df1['Public Remarks'].copy()\n",
    "df1.drop(['Public Remarks'], axis=1, inplace = True)\n",
    "\n",
    "# a bit of cleaning: filling with NaN's where not available, changing some words\n",
    "\n",
    "nlp_column = nlp_column.fillna('0')\n",
    "nlp_column_prep_1 = nlp_column.str.replace('&',' and ')\n",
    "nlp_column_prep_1 = nlp_column_prep_1.str.replace('%',' percent')\n",
    "nlp_column_prep_1 = nlp_column_prep_1.str.replace('*','')\n",
    "\n",
    "\n",
    "# replace all the digits with corresponding words: 5 -> five\n",
    "import re\n",
    "import num2words\n",
    "\n",
    "# this removes thousands delimiter. so 6,550 will be 6500\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+),(\\d+)', r'\\1\\2', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# # # these two lines change 4'' or 4 '' to 4 inch\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+) \\'\\'', r' \\1 inch ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+)\\'\\'', r' \\1 inch ', paragraph) for paragraph in nlp_column_prep_1]                           \n",
    "                       \n",
    "# these two lines change 3' or 3 ' to 3 feet\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+)\\'', r' \\1 foot', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'(\\d+) \\'', r' \\1 foot', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# this line changes feetx/feet x to feet by; inchx/inch x to inch by; ft. x to foor by\n",
    "nlp_column_prep_1 = [paragraph.replace('footx', 'feet by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('foot x', 'foot by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('inchx', 'inch by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('inch x', 'inch by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('ft. x', 'foot by') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('ft.', 'foot') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# change $number.00 to number dollars\n",
    "nlp_column_prep_1 = [re.sub(r'\\$(\\d+)\\.(\\d+)', r'\\1 dollars ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [re.sub(r'\\$(\\d+)', r'\\1 dollars ', paragraph) for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# here I MANUALLY change some of the non correct abbreviation for sqft and hwy\n",
    "nlp_column_prep_1 = [paragraph.replace('sg ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('s.f.', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('square-foot', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('sq ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "nlp_column_prep_1 = [paragraph.replace('sq.ft', 'sqft') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "nlp_column_prep_1 = [paragraph.replace('hwy', 'highway') for paragraph in nlp_column_prep_1]\n",
    "\n",
    "# this line changes all the numbers to their words\n",
    "nlp_column_prep_1 = [re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), paragraph) for paragraph in nlp_column]\n",
    "\n",
    "# tokenize these comments\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "nlp_column_prep_2 = [preprocess(paragraph) for paragraph in nlp_column_prep_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_embeddings_HF = model.encode(nlp_column_prep_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "paragraph_embeddings_transformed=0\n",
    "\n",
    "pca = PCA(n_components=15)\n",
    "paragraph_embeddings_transformed = pca.fit_transform(paragraph_embeddings_HF)\n",
    "\n",
    "paragraph_embeddings_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 130)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = 0, 0\n",
    "\n",
    "y = np.array(df1['Price'])\n",
    "\n",
    "# one-hot-encoding categorical features\n",
    "X1 = pd.get_dummies(df1[[ 'Total Baths', '# Rms',  'S/A',  'Area', 'Driveway Finish', 'Foundation', 'Type', 'Zoning', 'Sold Year', 'Sold Month']])\n",
    "\n",
    "X2 = df1.drop(['Total Baths', '# Rms', 'S/A', 'Area', 'Driveway Finish', 'Foundation', 'Type', 'Zoning', 'Sold Year', 'Sold Month', 'Price'], axis = 1)\n",
    "X2.fillna(-1)\n",
    "\n",
    "# generating a big preprocessed dataset including information from the text\n",
    "X = pd.concat([X1, X2], axis = 1)\n",
    "X = X.reset_index()\n",
    "del X['index']\n",
    "X = pd.concat([X, pd.DataFrame(paragraph_embeddings_transformed)], axis=1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tigrani/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tigrani/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/Users/tigrani/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, LassoCV\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state = 42)\n",
    "regr = 0\n",
    "\n",
    "### Model\n",
    "estimators = [\n",
    "#     ('lr1', LassoCV()),\n",
    "    ('lr2', RandomForestRegressor(n_estimators=7, random_state = 42, n_jobs=-1)),\n",
    "    ('lr3', xgb.XGBRegressor(n_estimators=73, learning_rate=0.1, gamma=0, subsample=0.75, colsample_bytree=1, random_state = 42)),\n",
    "#     ('lr4', DecisionTreeRegressor(random_state=0))\n",
    "    ]\n",
    "regr = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print('model fitted')\n",
    "\n",
    "y_test_pred = np.round(regr.predict(X_test))\n",
    "y_train_pred = np.round(regr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for test dataset:\n",
      "23.6 % of predited values has <= 2 % accuracy.\n",
      "32.1 % of predited values has <= 3 % accuracy.\n",
      "48.1 % of predited values has <= 5 % accuracy.\n",
      "72.6 % of predited values has <= 10 % accuracy.\n",
      "91.5 % of predited values has <= 20 % accuracy.\n",
      "\n",
      "\n",
      "Results for train dataset (to check if we have overfitting or the results are comparable with those on test dataset):\n",
      "74.5 % of predited values has <= 2 % accuracy.\n",
      "87.7 % of predited values has <= 3 % accuracy.\n",
      "97.6 % of predited values has <= 5 % accuracy.\n",
      "100.0 % of predited values has <= 10 % accuracy.\n",
      "100.0 % of predited values has <= 20 % accuracy.\n"
     ]
    }
   ],
   "source": [
    "# now metrics:\n",
    "\n",
    "print('Results for test dataset:')\n",
    "results_score(y_test, y_test_pred)\n",
    "\n",
    "print('\\n')\n",
    "print('Results for train dataset (to check if we have overfitting or the results are comparable with those on test dataset):')\n",
    "results_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error, results on test dataset:\n",
      "7.92398007958533\n",
      "\n",
      "\n",
      "Mean absolute percentage error, results on train dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0998728494015029"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute percentage error\n",
    "\n",
    "print('Mean absolute percentage error, results on test dataset:')\n",
    "print(mean_absolute_percentage_error(y_test, y_test_pred))\n",
    "\n",
    "print('\\n')\n",
    "print('Mean absolute percentage error, results on train dataset:')\n",
    "mean_absolute_percentage_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median absolute percentage error, results on test dataset:\n",
      "5.271095406360423\n",
      "\n",
      "\n",
      "Median absolute percentage error, results on train dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9801123595505618"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Median absolute percentage error\n",
    "\n",
    "print('Median absolute percentage error, results on test dataset:')\n",
    "print(median_absolute_percentage_error(y_test, y_test_pred))\n",
    "\n",
    "print('\\n')\n",
    "print('Median absolute percentage error, results on train dataset:')\n",
    "median_absolute_percentage_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights 1: about paragraph embeddings using NLP techincs\n",
    "\n",
    "What here we do: take all the paragraphs, train a machine-learned NLP model which is able to represent paragraphs in terms of (in this case) 50-dimensional vector which is in fact giving the context of the paragraph. The model is called Doc2Vec, it is being trained on our Public Remarks and it is expected that it is able to catch similarity between texts (in fact one of the main tools used to check similarity between texts).\n",
    "One big advantage of Doc2Vec model is that it is not very sensitive to bad non-correct words, noisy and not cleaned data. \n",
    "\n",
    "Similarity scores presented above are not very representative as this will be used jointly with the similarity ranking based on features of properties.\n",
    "\n",
    "#### Update from Dec 22 after adding predictions of property prices using ONLY their Public Remarks\n",
    "\n",
    "As we see this works, we are able to make not bad predictions ONLY using the information from Public Remarks, without knowing number of bedrooms, etc.etc.etc. This means, that the embeddings generated via NLP are giving some information.\n",
    "I've tried the same tactics using also previously developed fasttext embeddings from 3. NLP added to baseline solution file as well as playing with the Doc2Vec embeddings (this file) vector lenghts, training epochs, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update from Feb 22 after adding HuggingFace predictions and training ML model from baseline solution taking also NLP \n",
    "\n",
    "HuggingFace embeddings are much more better than Doc2Vec ones, give much better results and algorithms are able to train on them. And, even gives better results (some few procents of better predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
