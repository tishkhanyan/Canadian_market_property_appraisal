{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property appraisal ML project.\n",
    "## Phase 2: adding NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset has 558 data lines and 27 features:\n",
      "\n",
      "\n",
      "['Address', 'distance', 'acessibility', 'S/A', 'Price', 'Sold Date', 'Days On Market', 'Age', 'Area', 'Total Bedrooms', 'Total Baths', 'Lot Sz (Sq.Ft.)', 'Floor Area -Grand Total', 'Driveway Finish', 'Floor Area - Unfinished', 'Foundation', 'Floor Area Fin - Basement', 'Zoning', 'Parking Places - Covered', '# Rms', 'No. Floor Levels', 'Frontage - Feet', 'Depth', 'Type', 'Unnamed: 30', 'Unnamed: 31', 'Public Remarks']\n"
     ]
    }
   ],
   "source": [
    "# just reading the first sheet\n",
    "df1 = pd.read_csv(\"0. F20 P1-Table 1.csv\", na_values=['nan'])\n",
    "\n",
    "# deleting yellow columns\n",
    "df1.drop(['Status', 'For Tax Year', 'Gross Taxes', 'Original Price', 'List Price', 'GST Incl'], axis = 1, inplace = True)\n",
    "\n",
    "# size of our dataset\n",
    "print('Our dataset has', len(df1), 'data lines and', len(df1.columns.tolist()), 'features:')\n",
    "print('\\n')\n",
    "print(df1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the feature: distance\n",
      "Dropping the feature: acessibility\n",
      "Dropping the feature: Unnamed: 30\n",
      "Dropping the feature: Unnamed: 31\n",
      "\n",
      "\n",
      "Features left:\n",
      "['Address', 'S/A', 'Price', 'Days On Market', 'Age', 'Area', 'Total Bedrooms', 'Total Baths', 'Lot Sz (Sq.Ft.)', 'Floor Area -Grand Total', 'Driveway Finish', 'Floor Area - Unfinished', 'Foundation', 'Floor Area Fin - Basement', 'Zoning', 'Parking Places - Covered', '# Rms', 'No. Floor Levels', 'Frontage - Feet', 'Depth', 'Type', 'Public Remarks']\n",
      "\n",
      "\n",
      "Now we have 22 features and their types:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataTypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Address</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S/A</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days On Market</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Bedrooms</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Baths</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot Sz (Sq.Ft.)</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area -Grand Total</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Driveway Finish</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area - Unfinished</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floor Area Fin - Basement</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoning</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parking Places - Covered</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Rms</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. Floor Levels</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frontage - Feet</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public Remarks</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          DataTypes\n",
       "Address                      object\n",
       "S/A                          object\n",
       "Price                        object\n",
       "Days On Market                int64\n",
       "Age                           int64\n",
       "Area                         object\n",
       "Total Bedrooms                int64\n",
       "Total Baths                   int64\n",
       "Lot Sz (Sq.Ft.)              object\n",
       "Floor Area -Grand Total      object\n",
       "Driveway Finish              object\n",
       "Floor Area - Unfinished      object\n",
       "Foundation                   object\n",
       "Floor Area Fin - Basement    object\n",
       "Zoning                       object\n",
       "Parking Places - Covered    float64\n",
       "# Rms                         int64\n",
       "No. Floor Levels              int64\n",
       "Frontage - Feet              object\n",
       "Depth                        object\n",
       "Type                         object\n",
       "Public Remarks               object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the columns with more than 90% NAs\n",
    "moreThan = []\n",
    "\n",
    "for feature in df1:\n",
    "    if df1[feature].isna().sum() / df1.shape[0] > 0.9:\n",
    "        moreThan.append(feature)\n",
    "        print(\"Dropping the feature:\", feature)\n",
    "df1.drop(moreThan, axis = 1, inplace = True)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# dropping the columns that are not insightful: Days On Market, Public Remarks\n",
    "# df1.drop(['Sold Date', 'Public Remarks'], axis=1, inplace = True)\n",
    "df1.drop(['Sold Date'], axis=1, inplace = True)\n",
    "\n",
    "columns_names = df1.columns.tolist()\n",
    "\n",
    "print(\"Features left:\")\n",
    "print(columns_names)\n",
    "print('\\n')\n",
    "print(\"Now we have\", len(columns_names), \"features and their types:\")\n",
    "\n",
    "# types of our columns\n",
    "pd.DataFrame(df1.dtypes, columns=['DataTypes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is not cleaned!!! so we have to do something with that. \n",
    "# some features like Depth contain expressions like \"99X44X32\"\n",
    "\n",
    "# a bit of cleanup\n",
    "\n",
    "# in Address we need to take only the name of avenue \n",
    "df1['Address'] = df1['Address'].str.split(\" \", 1).str[-1] \n",
    "\n",
    "# S/A nothing to do\n",
    "\n",
    "# Price: remove $ and ,\n",
    "df1['Price'] = df1['Price'].str.replace('$','')\n",
    "df1['Price'] = df1['Price'].str.replace(',','')\n",
    "df1['Price'] = df1['Price'].astype(float)\n",
    "y = df1['Price']\n",
    "# df1 = df1.drop(['Price'], axis=1)\n",
    "\n",
    "# Days On Market nothing to do\n",
    "\n",
    "# Age: delete outliers\n",
    "df1['Age'][df1['Age'] > 100] == 0 ### or -1\n",
    "\n",
    "# Area, Total Bedrooms, Total Baths: nothing to do\n",
    "\n",
    "# Lot Sz (Sq.Ft.): remove , and .00\n",
    "df1['Lot Sz (Sq.Ft.)'] = df1['Lot Sz (Sq.Ft.)'].str.replace(',', '')\n",
    "df1['Lot Sz (Sq.Ft.)'] = df1['Lot Sz (Sq.Ft.)'].str.replace('.00', '')\n",
    "df1['Lot Sz (Sq.Ft.)'] = df1['Lot Sz (Sq.Ft.)'].astype(float)\n",
    "\n",
    "# Floor Area -Grand Total: remove ,\n",
    "df1['Floor Area -Grand Total'] = df1['Floor Area -Grand Total'].str.replace(',', '')\n",
    "df1['Floor Area -Grand Total'] = df1['Floor Area -Grand Total'].astype(float)\n",
    "\n",
    "# Driveway Finish: replace nan's with Unknowns\n",
    "df1['Driveway Finish'] = df1['Floor Area -Grand Total'].fillna('Unknown')\n",
    "\n",
    "# Floor Area -Grand Total: remove ,\n",
    "df1['Floor Area - Unfinished'] = df1['Floor Area - Unfinished'].str.replace(',', '')\n",
    "df1['Floor Area - Unfinished'] = df1['Floor Area - Unfinished'].astype(float)\n",
    "\n",
    "# Foundation: nothing to do\n",
    "\n",
    "# Floor Area Fin - Basement: remove ,\n",
    "df1['Floor Area Fin - Basement'] = df1['Floor Area Fin - Basement'].str.replace(',', '')\n",
    "df1['Floor Area Fin - Basement'] = df1['Floor Area Fin - Basement'].astype(float)\n",
    "\n",
    "# Zoning: maybe take a loot on intersection of two columns?!\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('1ACRER', 'RA')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('1 AR', 'RA')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('A1', 'A-1')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('A2', 'A-2')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RF13', 'RF-13')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RHG', 'RH-G')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('RS-1', 'RS1')\n",
    "df1['Zoning'] = df1['Zoning'].str.replace('SING/F', 'SING')\n",
    "\n",
    "# Parking Places - Covered: change nan's with 0 or -1\n",
    "df1['Parking Places - Covered'] = df1['Parking Places - Covered'].fillna(0) ### or -1\n",
    "\n",
    "# # Rms, No. Floor Levels: nothing to do\n",
    "\n",
    "# Frontage - Feet: remove , and change nan with 0 oe -1\n",
    "df1['Frontage - Feet'] = df1['Frontage - Feet'].str.replace(',', '')\n",
    "df1['Frontage - Feet'] = df1['Frontage - Feet'].astype(float)\n",
    "df1['Frontage - Feet'] = df1['Frontage - Feet'].fillna(0) ### or -1\n",
    "\n",
    "# Depth: to work out!!!! now dropping\n",
    "df1 = df1.drop(['Depth'], axis=1)\n",
    "\n",
    "# Type: nothing to do \n",
    "\n",
    "# ooobj = df1['Depth']\n",
    "# Counter(ooobj).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below I do NLP processing on \"Public Remarks\" column using two techincs: \n",
    "# 1. Making a bag of words\n",
    "# 2. using FastText wiki embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Public Remarks column has 755 different words.\n",
      "\n",
      "\n",
      "Here is an example how the above NLP works. We take this line:\n",
      "Investor's alert. 3 bedroom tenanted home with lots of potential for holding and rebuilding. This home sits on 2 lots with a bright south facing front yard. Each lot is 2500 sqft and adds up to a total of 5000 sqft. The back yard is fenced and quiet. Perfect for holding and building 1 or 2 homes later. Enquire at the City about your building options. Location is very convenient: close to School, community centre and Scott Road skytrain station. Short drive to get to Patullo bridge and King George highway and South Perimeter road. Quiet home at the end of a no-thru road. Home is tenanted, please drive by first before scheduling a showing.\n",
      "\n",
      "And transfer it to matrix of numbers: [[  0   0  32 105 658 345 739 415 473 530 283 344  69   0   0 345 605 480\n",
      "   27 415 739  46 124 618 257 294   0   0 414 372   0 626  69   0 694 674\n",
      "   46 680 473   0   0   0  88 747 372 267  69   0   0 283 344  69 130  20\n",
      "  488  27 346   0   0  81 662   0   0 752 130   0   0 372 708   0 160 674\n",
      "    0 165 154  69   0   0 612   0   0 213 674   0 674   0 122  69   0   0\n",
      "  341  69   0   0   0   0 345  81 662 228 473  46   0   0   0 372   0 522\n",
      "  213 137 275 109   0  46   0]]\n",
      "\n",
      "\n",
      "The overall shape of the NLPed matrix, i.e. we transfered one column of Public Remarks to a matrix of shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(558, 183)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling missing elements\n",
    "nlp_column = df1[\"Public Remarks\"].fillna('NaN')\n",
    "\n",
    "# making standard tokenization process\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "nlp_column_punc_tokenized = [ preprocess(string) for string in nlp_column ]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "\n",
    "nlp_tokenized = ([word_tokenize(i) for i in nlp_column_punc_tokenized])\n",
    "\n",
    "#then a bit of cleanup of tokenized elements\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "tokenized_words_flatt = list(itertools.chain(*nlp_tokenized))\n",
    "token_counts = Counter(tokenized_words_flatt)\n",
    "\n",
    "# deleting words that occur less than 10 times\n",
    "min_count = 10\n",
    "\n",
    "from itertools import dropwhile\n",
    "for key, count in dropwhile(lambda key_count: key_count[1] >= min_count, token_counts.most_common()):\n",
    "    del token_counts[key]\n",
    "    \n",
    "tokens = token_counts.keys()\n",
    "\n",
    "# add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Our Public Remarks column has\", len(tokens), \"different words.\")\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert UNK in tokens\n",
    "\n",
    "# making a dictionary of words and their numbers\n",
    "token_to_id = dict(zip(tokens, range(len(tokens))))\n",
    "\n",
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "# this function in fact transfers line of text into a matrix of numbers \n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Here is an example how the above NLP works. We take this line:\")\n",
    "print('\\n'.join(nlp_column[::100000].values), end='\\n\\n')\n",
    "print(\"And transfer it to matrix of numbers:\", as_matrix(nlp_column[::100000]))\n",
    "\n",
    "\n",
    "# finally, I do this \n",
    "X_nlp = as_matrix(nlp_tokenized, max_len=1000)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"The overall shape of the NLPed matrix, i.e. we transfered one column of Public Remarks to a matrix of shape:\")\n",
    "np.shape(X_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 556)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### then we get back to the original baseline solution\n",
    "# one-hot-encoding categorical features\n",
    "X1 = pd.get_dummies(df1[['Address', 'S/A', 'Area', 'Foundation', 'Zoning', 'Type']])\n",
    "\n",
    "# preprocessing the price feature\n",
    "y = df1['Price']\n",
    "\n",
    "# making polynomial transformation of numerical features\n",
    "X2 = df1.drop(['Address', 'S/A', 'Area', 'Foundation', 'Zoning', 'Type', 'Price', 'Public Remarks'], axis = 1)\n",
    "X2.fillna(0) ### or -1\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X2_2 = poly.fit_transform(X2)\n",
    "\n",
    "X2_3 = pd.DataFrame(X2_2, columns = poly.get_feature_names(X2.columns))\n",
    "X2_3 = X2_3.drop(['1'], axis = 1)\n",
    "\n",
    "X_nlp_df = pd.DataFrame(X_nlp)\n",
    "\n",
    "# generating a big preprocessed dataset\n",
    "X = pd.concat([X1, X2_3, X_nlp_df], axis = 1)\n",
    "\n",
    "# rescaling it\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# norm = MinMaxScaler().fit(X)\n",
    "norm = StandardScaler().fit(X)\n",
    "X = pd.DataFrame(columns = X.columns, data = norm.transform(X))\n",
    "\n",
    "# finally, we have 556 features (the case from baseline solution file has 373 features)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for linear regression: 26572.373568694333\n",
      "RMSE for random forest regression: 68397.07523001879\n",
      "\n",
      "\n",
      "weighted model: 0.8 * linear regressor + 0.19999999999999996 random forest regressor\n",
      "RMSE for weighted regressor: 27389.49835234957\n",
      "\n",
      "\n",
      "plotting scatter plots between predicted and actual prices to see if out model is good:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7facdd924ee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's make the same simple regressions on this\n",
    "\n",
    "# calculate the logarithm of price\n",
    "Y = np.log1p(y)\n",
    "\n",
    "\n",
    "# LinearRegression model\n",
    "lr = LinearRegression()\n",
    "model_lr = lr.fit(X, Y)\n",
    "\n",
    "predictions_lr = model_lr.predict(X)\n",
    "print(\"RMSE for linear regression:\", np.sqrt(mean_squared_error(y, np.expm1(predictions_lr))))\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "model_rf = rf.fit(X, Y)\n",
    "\n",
    "predictions_rf = model_rf.predict(X)\n",
    "print(\"RMSE for random forest regression:\", np.sqrt(mean_squared_error(y, np.expm1(predictions_rf))))\n",
    "\n",
    "\n",
    "# let's take some weighted sum of these two regressions' predictions\n",
    "weight_coeff = 0.8\n",
    "predictions = (weight_coeff * predictions_lr + (1 - weight_coeff) * predictions_rf)\n",
    "print('\\n')\n",
    "print(\"weighted model:\", weight_coeff, \"* linear regressor +\", 1 - weight_coeff, \"random forest regressor\" )\n",
    "print(\"RMSE for weighted regressor:\", np.sqrt(mean_squared_error(y, np.expm1(predictions))))\n",
    "\n",
    "# scatter plots\n",
    "print('\\n')\n",
    "print(\"plotting scatter plots between predicted and actual prices to see if out model is good:\")\n",
    "plt.scatter(y, np.expm1(predictions_lr))\n",
    "plt.scatter(y, np.expm1(predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of predictions accuracy: [<2%, 2 - 3%, 3 - 5%, 5 - 10%, >10%]\n",
      "[70.3, 15.1, 10.9, 3.6, 0.2]\n",
      "\n",
      "\n",
      "% of predictions, <=2% accuracy: 70.3\n",
      "% of predictions, <=3% accuracy: 85.39999999999999\n",
      "% of predictions, <=5% accuracy: 96.3\n",
      "% of predictions, 5-10% accuracy: 3.6\n",
      "% of predictions,  >10% accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "# finally, let's check what we have\n",
    "y_final = np.abs(np.expm1(predictions) - y)/(np.expm1(predictions)) * 100\n",
    "\n",
    "final_matrix = [0, 0, 0, 0, 0]\n",
    "for i in y_final:\n",
    "    if i <= 2:\n",
    "        final_matrix[0]+=1\n",
    "    elif i <= 3:\n",
    "        final_matrix[1]+=1\n",
    "    elif i <= 5:\n",
    "        final_matrix[2]+=1\n",
    "    elif i <= 10:\n",
    "        final_matrix[3]+=1\n",
    "    else:\n",
    "        final_matrix[4]+=1\n",
    "        \n",
    "for i in range(5):\n",
    "    final_matrix[i] = np.round(final_matrix[i]/len(y_final) * 100, 1)\n",
    "    \n",
    "print(\"% of predictions accuracy: [<2%, 2 - 3%, 3 - 5%, 5 - 10%, >10%]\")\n",
    "print(final_matrix)\n",
    "print('\\n')\n",
    "print(\"% of predictions, <=2% accuracy:\", np.sum(final_matrix[:1]))\n",
    "print(\"% of predictions, <=3% accuracy:\", np.sum(final_matrix[:2]))\n",
    "print(\"% of predictions, <=5% accuracy:\", np.sum(final_matrix[:3]))\n",
    "print(\"% of predictions, 5-10% accuracy:\", np.sum(final_matrix[3]))\n",
    "print(\"% of predictions,  >10% accuracy:\", np.sum(final_matrix[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of predictions accuracy: [<2%, 2 - 3%, 3 - 5%, 5 - 10%, >10%]\n",
      "[51.4, 15.4, 17.6, 12.9, 2.7]\n",
      "\n",
      "\n",
      "% of predictions, <=2% accuracy: 51.4\n",
      "% of predictions, <=3% accuracy: 66.8\n",
      "% of predictions, <=5% accuracy: 84.4\n",
      "% of predictions, 5-10% accuracy: 12.9\n",
      "% of predictions,  >10% accuracy: 2.7\n"
     ]
    }
   ],
   "source": [
    "# recalling the output for baseline solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tigrani/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTTEXT is loaded.\n"
     ]
    }
   ],
   "source": [
    "# now I do a better NLP using gensim fasttext embeddings for sentences.\n",
    "# An advantage is this will give also the context of the words + will work better for unseen words\n",
    "\n",
    "import gensim.downloader \n",
    "embeddings = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")\n",
    "print(\"FASTTEXT is loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public Remarcks culomn is transformed to a matrix of form =  (558, 300)\n"
     ]
    }
   ],
   "source": [
    "# using the same NOT PROCESSED Public Remarks \n",
    "# nlp_column\n",
    "\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "nlp_column_punc_tokenized = [ preprocess(string) for string in nlp_column ]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# here is my function that generates the word embeddings\n",
    "def vectorize_sum(comment):\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    \n",
    "    tokenized_comment = word_tokenize(comment)\n",
    "    \n",
    "    for word in tokenized_comment:\n",
    "        if word in (embeddings.key_to_index):\n",
    "            features += embeddings.get_vector(word)\n",
    "        else: ## this is for the cases like '``'\n",
    "            pass\n",
    "    \n",
    "    return features\n",
    "\n",
    "X_fasttext_nlp = np.stack([vectorize_sum(text) for text in nlp_column_punc_tokenized])\n",
    "\n",
    "print(\"Public Remarcks culomn is transformed to a matrix of form = \", np.shape(X_fasttext_nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558, 673)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding this to the dataset\n",
    "X_fasttext_df = pd.DataFrame(X_fasttext_nlp)\n",
    "X = pd.concat([X1, X2_3, X_fasttext_df], axis = 1)\n",
    "\n",
    "# rescaling it\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# norm = MinMaxScaler().fit(X)\n",
    "norm = StandardScaler().fit(X)\n",
    "X = pd.DataFrame(columns = X.columns, data = norm.transform(X))\n",
    "\n",
    "# finally, we have 673 features (the case from baseline solution file has 373 features)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for linear regression: 2.0891571911920454e-08\n",
      "RMSE for random forest regression: 72846.25160312455\n",
      "\n",
      "\n",
      "weighted model: 0.8 * linear regressor + 0.19999999999999996 random forest regressor\n",
      "RMSE for weighted regressor: 15697.800724189454\n",
      "\n",
      "\n",
      "plotting scatter plots between predicted and actual prices to see if out model is good:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7facc51bde50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's make the same simple regressions on this\n",
    "\n",
    "# calculate the logarithm of price\n",
    "Y = np.log1p(y)\n",
    "\n",
    "\n",
    "# LinearRegression model\n",
    "lr = LinearRegression()\n",
    "model_lr = lr.fit(X, Y)\n",
    "\n",
    "predictions_lr = model_lr.predict(X)\n",
    "print(\"RMSE for linear regression:\", np.sqrt(mean_squared_error(y, np.expm1(predictions_lr))))\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "model_rf = rf.fit(X, Y)\n",
    "\n",
    "predictions_rf = model_rf.predict(X)\n",
    "print(\"RMSE for random forest regression:\", np.sqrt(mean_squared_error(y, np.expm1(predictions_rf))))\n",
    "\n",
    "\n",
    "# let's take some weighted sum of these two regressions' predictions\n",
    "weight_coeff = 0.8\n",
    "predictions = (weight_coeff * predictions_lr + (1 - weight_coeff) * predictions_rf)\n",
    "print('\\n')\n",
    "print(\"weighted model:\", weight_coeff, \"* linear regressor +\", 1 - weight_coeff, \"random forest regressor\" )\n",
    "print(\"RMSE for weighted regressor:\", np.sqrt(mean_squared_error(y, np.expm1(predictions))))\n",
    "\n",
    "# scatter plots\n",
    "print('\\n')\n",
    "print(\"plotting scatter plots between predicted and actual prices to see if out model is good:\")\n",
    "plt.scatter(y, np.expm1(predictions_lr))\n",
    "plt.scatter(y, np.expm1(predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of predictions accuracy: [<2%, 2 - 3%, 3 - 5%, 5 - 10%, >10%]\n",
      "[95.3, 2.5, 2.0, 0.2, 0.0]\n",
      "\n",
      "\n",
      "% of predictions, <=2% accuracy: 95.3\n",
      "% of predictions, <=3% accuracy: 97.8\n",
      "% of predictions, <=5% accuracy: 99.8\n",
      "% of predictions, 5-10% accuracy: 0.2\n",
      "% of predictions,  >10% accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# finally, let's check what we have\n",
    "y_final = np.abs(np.expm1(predictions) - y)/(np.expm1(predictions)) * 100\n",
    "\n",
    "final_matrix = [0, 0, 0, 0, 0]\n",
    "for i in y_final:\n",
    "    if i <= 2:\n",
    "        final_matrix[0]+=1\n",
    "    elif i <= 3:\n",
    "        final_matrix[1]+=1\n",
    "    elif i <= 5:\n",
    "        final_matrix[2]+=1\n",
    "    elif i <= 10:\n",
    "        final_matrix[3]+=1\n",
    "    else:\n",
    "        final_matrix[4]+=1\n",
    "        \n",
    "for i in range(5):\n",
    "    final_matrix[i] = np.round(final_matrix[i]/len(y_final) * 100, 1)\n",
    "    \n",
    "print(\"% of predictions accuracy: [<2%, 2 - 3%, 3 - 5%, 5 - 10%, >10%]\")\n",
    "print(final_matrix)\n",
    "print('\\n')\n",
    "print(\"% of predictions, <=2% accuracy:\", np.sum(final_matrix[:1]))\n",
    "print(\"% of predictions, <=3% accuracy:\", np.sum(final_matrix[:2]))\n",
    "print(\"% of predictions, <=5% accuracy:\", np.sum(final_matrix[:3]))\n",
    "print(\"% of predictions, 5-10% accuracy:\", np.sum(final_matrix[3]))\n",
    "print(\"% of predictions,  >10% accuracy:\", np.sum(final_matrix[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights from this step: now we have at least two NLP subalgorithms that are generating additional information.\n",
    "# In fact the numbers above are showing almost nothing as the dataset initially is small and feeding it (having say 556 datapoints with 673 features)\n",
    "# to any ML model will immidiately bring to overfitting. \n",
    "\n",
    "# However, these NLP technics will be used for the next step that is the similarity ranking algorithm: here I'll use my already developed one for similarity,\n",
    "# add the NLP part and strenghten the algorithm with comments from John."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
